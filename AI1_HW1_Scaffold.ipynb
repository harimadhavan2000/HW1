{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn36zSjrA98K"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1WpIuwT7ActKDLTILNYc4L1_2s20e8yMO\" width=300/> \n",
        "\n",
        "# AI-1: ML/AI Basics\n",
        "## Homework 1: kNN and Linear Regression\n",
        "\n",
        "**AI1 Cohort 5**<br/>\n",
        "**Univ.AI**<br/>\n",
        "**Instructor**: Dr. Pavlos Protopapas<br />\n",
        "**Maximum Score**: 50\n",
        "\n",
        "<hr style=\"height:2.4pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJZfDyaVA98P"
      },
      "source": [
        "## Name of people who have worked on this homework: \n",
        "Hari Krishna; Shubham Deshmukh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa0t4AHyA98P"
      },
      "source": [
        "## [Optional] Google Colab notebook link with any other affiliated links:\n",
        "https://colab.research.google.com/github/harimadhavan2000/HW1/blob/master/AI1_HW1_Scaffold.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsuL0iHYA98Q"
      },
      "source": [
        "<hr style=\"height:2.4pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G322Og4WA98Q"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eebm4IGA98Q"
      },
      "source": [
        "\n",
        "- This homework is a jupyter notebook. Download and work on it in your local machine or you can work on it on Google Colab.\n",
        "\n",
        "- This homework should be worked on in pairs.\n",
        "\n",
        "- To submit the homework, either one of you upload the working notebook on Edstem and click the submit button on the bottom right corner.\n",
        "\n",
        "- Homework should be submitted by only one student in a team of two. If both teammates submit, scores will be penalized. \n",
        "\n",
        "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. \n",
        "\n",
        "- If you decide to submit a colab notebook, ensure you have given **complete edit access** to the staff while submitting. Also add any data that requires reviewing on google drive and submit the link.\n",
        "\n",
        "- Submit the homework well before the given deadline. Submissions after the deadline will not be graded.\n",
        "\n",
        "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them.\n",
        "\n",
        "- Comment your code well. This would help the graders in case there is any issue with the notebook while running. It is important to remember that the graders will not troubleshoot your code. \n",
        "\n",
        "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
        "\n",
        "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example: \n",
        "```\n",
        "print(f'The R^2 is {R:.4f}')\n",
        "```\n",
        "- Your plots should include clear labels for the $x$ and $y$ axes as well as a descriptive title (\"MSE plot\" is not a descriptive title; \"95 % confidence interval of coefficients of polynomial degree 5\" is).\n",
        "\n",
        "- **Ensure you make appropriate plots for all the questions it is applicable to, regardless of it being explicitly asked for.**\n",
        "\n",
        "<span style=\"color:red\"> \n",
        "\n",
        "**IMPORTANT** \n",
        "\n",
        "- Plagiarism of code/blocks of text is not acceptable for any Univ.AI submissions.\n",
        "- You are allowed to refer a publicly available source of information for a SMALL chunk of code provided you cite it clearly. \n",
        "- Copying the code blatantly without attribution is not permitted under any case. \n",
        "- Sharing code between homework teams is strictly not allowed.\n",
        "In case of any confusion you are advised to ask the staff on the Ed forum rather than assume the course of action needed. \n",
        "- If caught plagiarizing, you risk expulsion from the program.\n",
        "</span>\n",
        "\n",
        "<hr style=\"height:2pt\">\n",
        "\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i67MjVDA98S"
      },
      "source": [
        "<h2> Overview </h2> \n",
        "\n",
        "This assignment is the first where you will go through the process of loading a dataset, splitting it in train,validation and test sets, \n",
        "pre-processing it, and finally using it to run models and evaluating your results. \n",
        "\n",
        "We have two different datasets, one with car data in **Part 1** and another with data from an Indian matrimonial web site in **Part 2**.\n",
        "\n",
        "For part 1, you will explore two simple methods for prediction,  **k-nearest neighbors regression (kNN)**, a *non-parametric* method, and **linear regression**, a *parametric* method. As you move towards Part 2 of the homework, you will work with multiple linear and polynomial regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKLfxWaVA98S"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9qbfFOJKA98U"
      },
      "outputs": [],
      "source": [
        "# Importing standard libraries\n",
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "import os\n",
        "import pathlib\n",
        "working_dir = pathlib.Path().absolute()\n",
        "os.chdir(working_dir)\n",
        "import numpy as np\n",
        "import operator\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Pandas tricks for better display\n",
        "pd.options.display.max_columns = 50  \n",
        "pd.options.display.max_rows = 500     \n",
        "pd.options.display.max_colwidth = 100\n",
        "pd.options.display.precision = 3\n",
        "\n",
        "# Part 2 imports \n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymcoCsvYA98U"
      },
      "outputs": [],
      "source": [
        "# Run this cell for more readable visuals \n",
        "large = 22; med = 16; small = 10\n",
        "params = {'axes.titlesize': large,\n",
        "          'legend.fontsize': med,\n",
        "          'figure.figsize': (16, 10),\n",
        "          'axes.labelsize': med,\n",
        "          'axes.titlesize': med,\n",
        "          'axes.linewidth': 2,\n",
        "          'xtick.labelsize': med,\n",
        "          'ytick.labelsize': med,\n",
        "          'figure.titlesize': large}\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "plt.rcParams.update(params)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so58Zk3AA98V"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h2 style=\"color:black;background-color:#F6E6E2\"> Part A: k-NN and Linear Regression [30 points total] </h2>    <br />\n",
        "\n",
        "\n",
        "### Problem Description: Predicting the Selling Price of Cars on CarDekho.com\n",
        "\n",
        "According to its website, **CarDekho.com** is India's leading car search venture. \n",
        "Its website and app carry rich automotive content such as expert reviews, \n",
        "detailed specs and prices, comparisons as well as videos and pictures of all car brands and models available in India. \n",
        "Each car has a **Current selling price**, which is the price for buying the car on this site, and a **MRP**, \n",
        "which is the retail price of the car. These two prices differ depending on factors such as brand, \n",
        "make year, mileage, condition, etc.  \n",
        "    \n",
        "#### DATASET\n",
        "\n",
        "The dataset contains 601 cars and is in file `car_dekho_full.csv`. It contains the following columns:\n",
        "\n",
        "- **Year** - make year (year the car was made), \n",
        "- **Current_Selling_Price** - current price of a car on CarDekho.com (in lakhs),\n",
        "- **MRP** - maximum retail price of a car (in lakhs),\n",
        "- **Kms_Driven** - number of kilometers\n",
        "\n",
        "Note: 1 *lakh*  is 100,000 Rupees in the Indian numbering system. Also, kilometers are used as a measure of distance instead of miles.\n",
        "\n",
        "#### Your Task: \n",
        "Predict the `Current_Selling_Price` from the other features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpJ-7KjVA98V"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "    \n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 1:   Exploratory Data Analysis (EDA) [10 points total] </h3>    <br />\n",
        "    \n",
        "To reach the goal of predicting the `Current_Selling_Price`, start by inspecting the dataset using Exploratory Data Analysis (EDA).\n",
        "\n",
        "\n",
        "Load the dataset, inspect it and answer the following questions: \n",
        "\n",
        "**1.1** [2pts] Which variables are quantitative, and which are categorical? \n",
        "    \n",
        "**1.2** [2pts] What are the means and standard deviations for `Current_Selling_Price` and `MRP`? \n",
        "    \n",
        "**1.3** [2pts] What is the range of Kilometers that the cars have? \n",
        "Note: The range is the difference between the maximum value and the minimum value.\n",
        "\n",
        "\n",
        "**1.4** [2pts] The goal of this part is to identify the best variable from which to predict our respone variable `Current Selling Price`. Plot a scatter plot between each predictor and reponse variable and examine the relationship between the predictors and `Current_Selling_Price`. Based on the plots, which is the  predictor that visually seems to best predict the `Current_Selling_Price`? \n",
        "    \n",
        "<br/><br/>\n",
        "Note: Label your axes.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR5NAMPzA98W"
      },
      "source": [
        "### Solutions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9CzmrJ4A98W"
      },
      "source": [
        "#### 1.1\n",
        "\n",
        "**Which variables are quantitative, and which are categorical?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/car_dekho_full.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgByyAN2A98W"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantitative -  Current_Selling_Price, MRP, Kms_Driven \\\n",
        "Categorical - Year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7BWoiEhA98X"
      },
      "source": [
        "#### 1.2\n",
        "\n",
        "**What are the means and standard deviations for Current_Selling_Price and MRP?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDIn47cFA98X"
      },
      "outputs": [],
      "source": [
        "# Name your variables as mean_csp, mean_mrp, std_csp, std_mrp\n",
        "\n",
        "# your code here\n",
        "mean_csp = df['Current_Selling_Price'].mean()\n",
        "mean_mrp = df['MRP'].mean()\n",
        "std_csp = df['Current_Selling_Price'].std()\n",
        "std_mrp = df['MRP'].std()\n",
        "\n",
        "# end your code here \n",
        "\n",
        "\n",
        "print (\"The mean Current Selling Price is\", mean_csp,\"lakhs\")\n",
        "print (\"The mean MRP is\", mean_mrp,'lakhs')\n",
        "print (\"The Standard Deviation of Current Selling Price is\", std_csp)\n",
        "print (\"The Standard Deviation of MRP is\", std_mrp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YI0WFJ5A98X"
      },
      "source": [
        "#### 1.3\n",
        "\n",
        "**What is the range of Kilometers that the cars have?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy8sx9szA98X"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "df['Kms_Driven'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The range is 500.000 -  213000.000 kilometers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cCoZ8GIA98X"
      },
      "source": [
        "#### 1.4\n",
        "\n",
        "**The goal of this part is to identify the best variable from which to predict our respone variable Current Selling Price. Plot a scatter plot between each predictor and reponse variable and examine the relationship between the predictors and Current_Selling_Price. Based on the plots, which is the predictor that visually seem to best predict the Current_Selling_Price?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS7xDbjOA98Y"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "indep_columns = df.columns.drop('Current_Selling_Price')\n",
        "for x in indep_columns:\n",
        "    plt.figure()\n",
        "    plt.scatter(df[x], df['Current_Selling_Price'])\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel('Current Selling Price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhMGXVB8A98Y"
      },
      "source": [
        "**Your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see from the above generated figures that MRP seems to have the best relationship with the CSP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Xzidz2A98Y"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 2:   k-Nearest Neighbors  [10 points total] </h3>    <br />\n",
        "\n",
        "We begin our modeling with k-Nearest Neighbors (kNN) regression. You may use `sklearn`'s built-in functions.\n",
        "<br /><br />\n",
        "**2.1** [6pts] In this part, we will model a kNN regression on the predictor chosen above (1.4) and the response variable `Current_Selling_Price`.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "- Split the dataset in train and test set with 75% training data and 25% testing data, using the random_state = 109. \n",
        "<br />\n",
        "- Fit a kNN regression model to the training set for the following 8 different values of $k$:  $k = 1,2,3,5,7,10,60,100$. \n",
        "<br />\n",
        "- Make 8 scatter plots of response vs. predictor for each $k$ arranged in a $4\\times2$ grid.  Each figure should have plots of the prediction from the k-NN regression and the actual data points on the same figure, as well as axis labels, title, and legend. Consider using the subplot functionality, unless you first try this and then decide that you have a clearer, cleaner way of communicating these plots.\n",
        "<br />\n",
        "- Evaluate the $MSE$ for the fitted models on both the training and test sets **for each $k$**.\n",
        "<br />\n",
        "- Plot both the training and test $MSE$ values as a function of $k$ on the same figure.  Again, the figure must have axis labels and a legend.\n",
        "<br />\n",
        "- Find the best model based on the test $MSE$ values.\n",
        "<br />\n",
        "- Evaluate and report the $R^2$ of the best model.\n",
        "\n",
        "</details>\n",
        "\n",
        "<br /><br />\n",
        "**2.2** [4pts] Discuss your results by answering the following questions.  You should answer the questions directly in a markdown cell of your notebook.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "- How does the value of $k$ affect the fitted model?\n",
        "<br />\n",
        "- If $n$ is the number of observations in the training set, what can you say about a k-NN regression model that uses $k = n$?  \n",
        "- Do the training and test $MSE$ plots exhibit different trends?  Explain how the value of $k$ influences the training and test $MSE$ values.\n",
        "<br />\n",
        "- Run the same code by changing the random seed during the train-test split. Do you always get the same answer? If not, why?\n",
        "\n",
        "</details>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GadNfbMZA98Z"
      },
      "source": [
        "### Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bUiAI-HA98Z"
      },
      "source": [
        "#### 2.1\n",
        "In this part, we will model a kNN regression on the predictor chosen above (1.4) and the response variable `Current_Selling_Price`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuGjvtlxA98Z"
      },
      "outputs": [],
      "source": [
        "#Choosing your predictor and response variable\n",
        "\n",
        "# your code here\n",
        "\n",
        "x = df['MRP'].values\n",
        "y = df['Current_Selling_Price'].values\n",
        "\n",
        "# end of your code here \n",
        "\n",
        "\n",
        "##Splitting the data into train and test sets with 75% training data and 25% testing data. Set random_state=109\n",
        "# your code here\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=109)\n",
        "\n",
        "# end of your code here  \n",
        "\n",
        "\n",
        "## Fit a kNN regression model to the training set for the following 8 different values of  ùëò :  ùëò=1,2,3,5,7,10,60,100 .\n",
        "## and make 8 scatter plots of response vs. predictor for each  ùëò , arranged in a  4√ó2  grid. \n",
        "## Each figure should have plots of the prediction from the k-NN regression and the actual data points on the same figure, as well as axis labels, title, and legend \n",
        "# your code here \n",
        "# Plotting\n",
        "\n",
        "for i in [1, 2, 3, 5, 7, 10, 60, 100]:\n",
        "    knn = KNeighborsRegressor(n_neighbors=i)\n",
        "    knn.fit(x_train.reshape(-1, 1), y_train)\n",
        "    y_pred = knn.predict(x_test.reshape(-1, 1))\n",
        "    plt.figure()\n",
        "    plt.scatter(x_test, y_test, label='Actual')\n",
        "    plt.scatter(x_test, y_pred, label='Predicted')\n",
        "    plt.xlabel('MRP')\n",
        "    plt.ylabel('Current Selling Price')\n",
        "    plt.title('k = {}'.format(i))\n",
        "    plt.legend()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7BBFslRA98Z"
      },
      "outputs": [],
      "source": [
        "# Now make the MSE plots\n",
        "# your code here\n",
        "\n",
        "mse = []\n",
        "for i in [1, 2, 3, 5, 7, 10, 60, 100]:\n",
        "    knn = KNeighborsRegressor(n_neighbors=i)\n",
        "    knn.fit(x_train.reshape(-1, 1), y_train)\n",
        "    y_pred = knn.predict(x_test.reshape(-1, 1))\n",
        "    mse.append(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "plt.scatter(range(8), mse)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Keg1yfowA98Z"
      },
      "outputs": [],
      "source": [
        "# Find the best model\n",
        "# your code here\n",
        "\n",
        "idx = np.array(mse).argmin()\n",
        "#k = 7 is the best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Syn9qCrA98a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "##Compute the R-squared for the best model\n",
        "# your code here\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=7)\n",
        "knn.fit(x_train.reshape(-1, 1), y_train)\n",
        "y_pred = knn.predict(x_test.reshape(-1, 1))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk3Y4j0bA98b"
      },
      "source": [
        "#### 2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS_Bqf9VA98b"
      },
      "source": [
        "**Your answer here**\n",
        "\n",
        "**a) How does the value of $k$ affect the fitted model?**\n",
        "<br />\n",
        "\n",
        "\n",
        "**b) If $n$ is the number of observations in the training set, what can you say about a k-NN regression model that uses $k = n$?**\n",
        "<br />\n",
        "\n",
        "**c) Do the training and test $MSE$ plots exhibit different trends?  Explain how the value of $k$ influences the training and test $MSE$ values.**\n",
        "<br />\n",
        "\n",
        "**d) Run the same code by changing the random seed during the train-test split. Do you always get the same answer? If not, why?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a) k is the number of neighbouring point choses to compute/predict the response at a point \\\n",
        "b) since $y = \\frac{1}{k} \\sum ^k _{i=0} x_i$ with $x_i$ are the k nearest neighbours, by substituting $k=n$ we get the trivial result that $y= \\bar x$; ie the mean value is the response at all points. \\\n",
        "c) the higher the k, the more uniform the response is with no attempt to fit each point, thus, the train error is high, and similarly so is the test error. for lower k, the train prediction attempts to fit each data point as closely as possible; so train error will be low, but due to this overfitting; the test error will be high. we aim to choose an optimum value to minimize test mse; thus k = 7. train error decreases with k; test error decreases to an optimum then increases. \\\n",
        "d) No, as the optimum value may change according to the model that arises from the split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl_RIZP9A98b"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 3:  Simple Linear Regression   [10 points total] </h3>   \n",
        "\n",
        "<br /><br />\n",
        "**3.1** [5pts] We will now fit our data using a linear regression model. Choose the same **predictor** and **response** variables used to model kNN regression.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "- You will use the same 75% training and 25% testing split of the data, using the random_state = 110. \n",
        "<br />\n",
        "- Run a Linear Regression model.\n",
        "<br />\n",
        "- Report the slope/coefficient and intercept values for the fitted linear model.\n",
        "<br />\n",
        "- Report the $MSE$ for the training and test sets and the $R^2$ from the test set.\n",
        "<br />\n",
        "- Plot the **residuals** $e = y_{train} - \\hat{y}_{train}$ of the model on the training set on the Y-axis and the response variable $y_{train}$ on the X-axis. Draw a horizontal line denoting the zero residual value on the Y-axis. Discuss the shape of the plot and what it shows about the quality of the model.\n",
        "<br /><br />\n",
        "    \n",
        "**Note:** Use the `sklearn` module for linear regression. This module has built-in functions to summarize the results of regression and produce residual plots. Create a `Linear Regression` model, use the `fit` method in the instance for fitting a linear regression model, and use the `predict` method to make predictions. As previously, you may use the `mean_squared_error` function to compute $MSE$.\n",
        "\n",
        "    \n",
        "</details>\n",
        "\n",
        "<br /><br />\n",
        "\n",
        "**3.2** [5pts] Discuss your results by answering the following questions.  \n",
        "    \n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>   \n",
        "- How does the test $MSE$ score compare with the best test $MSE$ value obtained with k-NN regression? \n",
        "<br />\n",
        "- What does the sign of the slope of the fitted linear model convey about the data? \n",
        "<br />\n",
        "- Based on the residual plot that you made, discuss whether or not the assumption of linearity is valid for this data.\n",
        "<details>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UdARtQLA98b"
      },
      "source": [
        "### Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti5sk5OJA98b"
      },
      "source": [
        "#### 3.1\n",
        "**Predict the selling price**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fR5mDlPGA98c"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "x = df['MRP'].values\n",
        "y = df['Current_Selling_Price'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=110)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2u47JvzA98c"
      },
      "outputs": [],
      "source": [
        "## Fit a linear model to the train data\n",
        "\n",
        "# your code here\n",
        "\n",
        "lreg = LinearRegression()\n",
        "lreg.fit(x_train.reshape(-1, 1), y_train)\n",
        "y_pred = lreg.predict(x_test.reshape(-1, 1))\n",
        "\n",
        "print(\"beta_1 and beta_0 are:\",  lreg.coef_[0], lreg.intercept_)\n",
        "print(\"the mse train is \", mean_squared_error(y_train, lreg.predict(x_train.reshape(-1, 1))))\n",
        "print(\"the mse test is \", mean_squared_error(y_test, y_pred))\n",
        "print(\"the r-squared on test is \", r2_score(y_test, y_pred))\n",
        "\n",
        "# end of your code here \n",
        "\n",
        "\n",
        "## Plot the **residuals** \n",
        "# your code here \n",
        "\n",
        "residual = y_test - y_pred\n",
        "plt.plot(x_test, residual, 'o')\n",
        "plt.plot(x_test, np.zeros(len(x_test)), 'r-')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we see that the residuals increase with x, so we may infer an increasing, i.e non constant variance in data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X6Tav-9A98c"
      },
      "source": [
        "#### 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRlyc91cA98c"
      },
      "source": [
        "**Your answer here**\n",
        "\n",
        "**a) How does the test $MSE$ score compare with the best test $MSE$ value obtained with k-NN regression?**\n",
        "<br />\n",
        "\n",
        "\n",
        "**b) What does the sign of the slope of the fitted linear model convey about the data?**\n",
        "<br />\n",
        "\n",
        "\n",
        "**c) Based on the residual plot that you made, discuss whether or not the assumption of linearity is valid for this data.\n",
        "<br />**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a)  it is worse than that of the best knn models \\\n",
        "b) positive corellations between MRP and selling price \\\n",
        "c) not valid as data is not of constant variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEbXCZwwA98c"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 4:  Linear Regression with Feature engineering [Optional] </h3>   \n",
        "\n",
        "<br /><br />\n",
        "**4.1** Creating a new variable from existing data: percentage depreciation.\n",
        "    \n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "Feature engineering involves transforming data into features that better represent the underlying problem to the predictive models. This results in improved model accuracy on unseen data. \n",
        "<br />\n",
        "Our previous regression model relates the Current selling price to the MRP of the car with the equation:\n",
        "<br /><br />\n",
        "$$CSP = \\beta_0 + \\beta_1*MRP$$\n",
        "<br />\n",
        "However, this linear equation does not incorparate other interesting variables such as the ```year of manufacture```, or the ```kms driven```, which maybe important factors that affect the overall price of the car. \n",
        "<br />\n",
        "Instead of using multi-linear analysis, we can perform some intelligent feature engineering to identify other simple linear relationships within our data.\n",
        "<br />\n",
        "From practical experience, we know that the percentage drop of a car's price is proportional to the age of the car ([more on car depreciation here](https://www.finder.com/what-is-car-depreciation)). \n",
        "<br />\n",
        "Hence, it makes sense to investigate this variable seperately and try to identify possible relationships with other variables.  \n",
        "<br />\n",
        "Define the percentage depreciation of the Current selling price to the MRP as follows:\n",
        "<br /><br />\n",
        "$$\\textrm{Percentage of the Selling Price}=perc =\\frac{MRP - Selling Price}{MRP}$$\n",
        "</details>\n",
        "    \n",
        "<br /><br />\n",
        "**4.2** Exploratory Data Analysis.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "For this section, we will consider `perc` to be our intermediate response variable. To understand the relationship between `perc` and our predictor variables we will perform EDA.\n",
        "<br /><br />\n",
        "Answer the following questions by plotting graphs.\n",
        "<br /><br />\n",
        "a) It is seen previosuly that there is a relationship between `Year` and `Current Selling Price`. Is the relationship between `Years` and `perc` the same. If not, how has it changed and why do you think so? Plot a scatter plot or any other plot of your choice and write your inferences.\n",
        "<br />\n",
        "b) Is the trend between the `MRP` and `perc` the same as that between `MRP` and `Current Selling Price`? Plot a scatter plot or any other plot of your choice and write your inferences.\n",
        "<br />\n",
        "c) Does there seem to be a relationship between `Kms_Driven` and `perc`? Plot a scatter plot or any other plot of your choice and write your inferences.\n",
        "<br />\n",
        "d) Which is the best predictor to predict `perc`, if there is one? Is it the same as that of `Current Selling price` or has it changed? Plot a scatter plot or any other plot of your choice and write your inferences.\n",
        "    \n",
        "</details>\n",
        "    \n",
        "<br /><br />\n",
        "    \n",
        "**4.3** Perform additional EDA.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "Feel free to use other plots and statistics to find the best predictor and/or understand the relationship between variables. One example is given below. It is a plot of `Current Selling Price` vs `Year` that is color coded based on the `Kms_Driven`. \n",
        "    \n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1cfXPPdh0qjy4X8jbt7G5vQAoXTnQfYH1\" width=600/> \n",
        "    \n",
        "</details>\n",
        "<br /><br /> \n",
        "    \n",
        "**4.4** Fitting a Linear Regression model.\n",
        "    \n",
        "<details>\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Click for instructions</b>\n",
        "</font>\n",
        "</summary>\n",
        "    \n",
        "Based on the previous EDA choose appropriate **feature** variable(s) and **response** variable.\n",
        "\n",
        "- Again, use split train-test sets with training data of 75% and testing data of 25%\n",
        "<br />\n",
        "- Fit a Linear Regression model for each of the predictors.\n",
        "<br />\n",
        "- Predict the model for the train and test data\n",
        "<br />\n",
        "- Plot a graph with the test data with predictor variable on the *x* axis and `perc` on the *y* axis. Also plot the fit curve. Ensure you use the correct labels and show the legend.\n",
        "<br />\n",
        "- Report the $MSE$ score from the training and test sets.\n",
        "<br />\n",
        "- Find the best model i.e. the best predictor based on the $MSE$ of each model.\n",
        "</details>\n",
        "<br /><br />\n",
        "\n",
        "**4.5** Predicting The Current Selling Price using ```perc``` \n",
        "<br /><br />\n",
        "After performing the above analysis, answer briefly as to why are we getting such a dramatic increase in the R2 score?\n",
        "    <br /><br />\n",
        " </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfI2ebnHA98d"
      },
      "source": [
        "### Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntXb6Z4iA98d"
      },
      "source": [
        "#### 4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXFSrFowA98d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Create a new column perc and add to the dataframe\n",
        "# your code here\n",
        "\n",
        "df['perc'] = (df['MRP'] - df['Current_Selling_Price'])/df['MRP']\n",
        "\n",
        "#Creating a new column perc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2wApDvLA98d"
      },
      "source": [
        "#### 4.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItfnuZpaA98d"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "plt.plot(df['Year'], df['Current_Selling_Price'], 'o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Current Selling Price')\n",
        "plt.figure()\n",
        "plt.plot(df['perc'], df['Current_Selling_Price'], '*')\n",
        "plt.xlabel('perc')\n",
        "plt.ylabel('Current Selling Price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tolG3FSMA98d"
      },
      "source": [
        "**Your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQwoopMA98d"
      },
      "source": [
        "# your code here\n",
        "the relationship between year and csp is roughly positive, the relationship between perc and csp is roughly negative, as expected. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHJVCVA7A98e"
      },
      "source": [
        "**Your answer here**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8d0pSzPA98e"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "#scatter plot between mrp and perc\n",
        "\n",
        "plt.plot(df['MRP'], df['perc'], 'o')\n",
        "plt.xlabel('MRP')\n",
        "plt.ylabel('perc')\n",
        "plt.figure()\n",
        "plt.plot(df['MRP'], df['Current_Selling_Price'], 'o')\n",
        "plt.xlabel('MRP')\n",
        "plt.ylabel('Current_Selling_Price')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(df['Kms_Driven'], df['perc'], 'o')\n",
        "plt.xlabel('Kms_Driven')\n",
        "plt.ylabel('perc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(df['Year'], df['perc'], 'o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('perc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlHpULtBA98e"
      },
      "source": [
        "**Your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnenWgDiA98e"
      },
      "source": [
        "#### 4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuvEKwaUA98e"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "arr = []\n",
        "for i in df.columns :\n",
        "    for j in df.columns:\n",
        "        if i != j:\n",
        "            x = df[i].values\n",
        "            y = df[j].values\n",
        "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state = 110)\n",
        "            lreg = LinearRegression()\n",
        "            lreg.fit(x_train.reshape(-1, 1), y_train)\n",
        "            y_pred = lreg.predict(x_test.reshape(-1, 1))\n",
        "            r2_sc = r2_score(y_test, y_pred)\n",
        "            arr.append([i, j, r2_sc])\n",
        "            #print(\"The r2 score between {} and {} is {}\".format(i, j, r2_sc))\n",
        "\n",
        "s = sorted(arr,key=lambda x: x[2], reverse=True)\n",
        "for ele in s:\n",
        "    print(\"The r2 score between {} and {} is {}\".format(ele[0], ele[1], ele[2]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The r2 score between Year and perc is 0.7175431933190926 \\\n",
        "The r2 score between perc and Year is 0.7156041273061939 \\\n",
        "The r2 score between Current_Selling_Price and MRP is 0.6630096092024362 \\\n",
        "The r2 score between MRP and Current_Selling_Price is 0.6276155728045865 \\\n",
        "The r2 score between perc and Kms_Driven is 0.4047006403971317 \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I38D-4wMA98e"
      },
      "source": [
        "#### 4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y70XLsItA98e"
      },
      "outputs": [],
      "source": [
        "# Linear Regression using Year as the reponse variable\n",
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CznHYdAZA98e"
      },
      "outputs": [],
      "source": [
        "# Linear Regression using MRP as the reponse variable\n",
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO61yq7qA98f"
      },
      "outputs": [],
      "source": [
        "# Linear Regression using KMs Driven as the reponse variable\n",
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for ix in ['Year', 'MRP', 'Kms_Driven', 'perc']:\n",
        "    x = df[ix].values\n",
        "    y = df['perc'].values\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=110)\n",
        "    lreg = LinearRegression()\n",
        "    lreg.fit(x_train.reshape(-1, 1), y_train)\n",
        "    y_pred = lreg.predict(x_test.reshape(-1, 1))\n",
        "    r2_sc = r2_score(y_test, y_pred)\n",
        "    print(\"R2 score for {} is {}\".format(ix, r2_sc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y4CosbfA98f"
      },
      "source": [
        "**Your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vhxbwc8A98f"
      },
      "source": [
        "#### 4.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYUJrg5qA98f"
      },
      "outputs": [],
      "source": [
        "#Linear Regression using Year as the reponse variable\n",
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get better R2 from using perc rather than CSP as perc is more responsive to other response variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpVhi01LA98f"
      },
      "source": [
        "**Your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3_jkn0kA98f"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h2 style=\"color:black;background-color:#F6E6E2\"> Part Œí :  Multi-Linear Regression [20 points total] </h2><br />\n",
        "\n",
        "\n",
        "### Problem Description: \n",
        "\n",
        "Analysis of publically available profiles on **simplymarry** to learn more about the biases, income disparity & other interesting trends in India. \n",
        "\n",
        "#### Dataset\n",
        "\n",
        "The dataset was aggregated from the **simplymarry** site.\n",
        "\n",
        "All the attributes refer to traits and preferences of the person looking for a spouse. \n",
        "\n",
        "- **age** - Age of person looking for a spouse\n",
        "- **gender** - Female:0, Male:1 \n",
        "- **height** - Height in inches\n",
        "- **bmi** - BMI calculated based on height and weight\n",
        "- **eating** - {'Doesn't Matter':0, 'Jain': 1, 'Vegetarian': 2, 'Vegetarian With Eggs': 3, 'Non Vegetarian': 4}\n",
        "- **family_type** - ('Doesn't Matter': 0, 'Others':3, 'Nuclear': 1, 'Joint family both parents': 2, 'Joint family only mother':2, 'Joint family father mother and brothers sisters':2, 'Joint family single parent brothers and or sisters':2, 'Joint family only father': 2)\n",
        "- **status** - If social status matters to the person looking for a spouse: {'Doesn't Matter': 0, 'Middle Class': 1, 'Upper Middle Class': 2, 'High Class': 3, 'Rich / Affluent': 4}\n",
        "- **manglik** - {'No': 0, 'Yes': 1, 'Do Not Know': 2} ([More on this feature](https://en.wikipedia.org/wiki/Mangala_Dosha))\n",
        "- **drinking** - {'Doesn't Matter':0, 'No': 1, 'Occasionally': 2, 'Yes': 3}\n",
        "- **complexion** - {'Very Fair ': 1, 'Fair ': 2, 'Wheatish Medium ': 4, 'Wheatish ':3, 'Dark':5}\n",
        "- **body** - {'Slim': 1, 'Average': 2, 'Heavy': 3, 'Athletic': 4}\n",
        "- **education** - {'High School':0, 'Some college':1,'Undergrad':2, 'Grad':3, 'Doctorate':4}\n",
        "- **city** - ('International': 1, 'Mumbai': 2, 'Delhi':3, 'Kolkata':4,'Bengaluru':5, 'Chennai':6, 'Hyderabad':7, 'Pune':8, 'Ahmedabad':9,'Surat':10, 'Vishakapatnam':11, 'Others':12)\n",
        "- **income** - {Annual income in dollars}\n",
        "\n",
        "*source: Harvard IACS*\n",
        "\n",
        "#### Sensitive attributes in the data\n",
        "\n",
        "It is thought that users are mostly sincere when stating their preferences about their desired partner, and are unlikely to hide any deeply held cultural or sociological biases in order to be perceived as being politically correct. This might take care of the problem with surveys where responses touching on social norms are notorious for self-report bias.\n",
        "\n",
        "This is a dataset designed to make you think about issues of bias and social issues in datasets. We hope that you will be able to derive insights into the above mentioned sociological biases. The data could potentially provide answers to interesting questions with associated policy ramifications, such as do these biases reduce among more educated users, or more urban users?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBdEXJyTA98g"
      },
      "outputs": [],
      "source": [
        "# Read the file named \"income_prediction.csv\"\n",
        "\n",
        "df = pd.read_csv('data/income_prediction.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm-eXinKA98g"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 5:   Using Data science to learn more about Indian society  [15 points total] </h3>    <br />\n",
        "\n",
        "\n",
        "First we are going to use simple analytics to learn more about Indian society with the help of this dataset.\n",
        "\n",
        "The idea is to use basic modeling based on averages & sample distributions to uncover suspected biases, such as gender, skin tone & manglik status.\n",
        "\n",
        "Answer the below questions using plots & simple statistics\n",
        "<br /><br />\n",
        "**5.1** [2pt] Is there a gender-bias for income of participants?\n",
        "<br /><br />\n",
        "**5.2** [2pt] Is there a correlation between income and skin complexion?\n",
        "<br /><br />\n",
        "**5.3** [2pt] Is there a discernible trend in the incomes of participants from different regions/cities?\n",
        "<br /><br />\n",
        "**5.4** [1pt] Is there a clear trend between BMI and the income?\n",
        "<br /><br />\n",
        "**5.5** [2pt] Does the level of education show a clear trend with income?\n",
        "<br /><br />\n",
        "**5.6** [2pt] Do any of the numeric attributes show a clear non-linear dependence with the amount of income?\n",
        "<br /><br />\n",
        "**5.7** [2pt] Is the income lower or high for those living in 'nuclear' families?\n",
        "<br /><br />\n",
        "**5.8** [2pt] Does being 'Manglik' negatively affect the income of participants?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2nAqiJ7A98g"
      },
      "source": [
        "### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGCppjz9A98g"
      },
      "source": [
        "#### 5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ7DKvkjA98g"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "gender_dict = {'Female':0, 'Male':1}\n",
        "print(df[df['gender']==1].shape[0], 'male')\n",
        "print(df[df['gender']==0].shape[0], 'female')\n",
        "plt.bar(range(len(gender_dict.keys())),df.groupby('gender').size(),  tick_label=list(gender_dict.keys()))\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('count')\n",
        "#yes, there is a overall gender imbalance with more men than women\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJdmvFPhA98g"
      },
      "source": [
        "#### 5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9fCkTO3A98h",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# you code here \n",
        "#correlation between income and skin complexion\n",
        "plt.scatter(df['income'], df['complexion'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.corrcoef(df['income'], df['complexion'])[1][0]\n",
        "# the correlation is -0.08, or very weakly negativez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxJ79gUWA98h"
      },
      "source": [
        "#### 5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm_eh1E1A98h"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "city_map = {'International': 1, 'Mumbai': 2, 'Delhi':3, 'Kolkata':4,'Bengaluru':5, 'Chennai':6, 'Hyderabad':7, 'Pune':8, 'Ahmedabad':9,'Surat':10, 'Vishakapatnam':11, 'Others':12}\n",
        "inv_dict = {v: k for k, v in city_map.items()}\n",
        "plt.figure(figsize = (20, 16))\n",
        "df.groupby('city')['income'].mean()\n",
        "plt.bar(range(len(inv_dict.keys())),df.groupby('city')['income'].mean(),  tick_label=list(city_map.keys()))\n",
        "plt.xlabel('city')\n",
        "plt.ylabel('income')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#thus, one can see that the income is highest in International and lowest in Others, and there is a trend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqF_vRaxA98h"
      },
      "source": [
        "#### 5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ewgrE2sEA98h"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "plt.plot(df['bmi'], df['income'], 'o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.corrcoef(df['bmi'], df['income'])\n",
        "# 0.02882135, weak correlation between bmi and income"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFzwZTdA98h"
      },
      "source": [
        "#### 5.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ed_dict = {'High School':0, 'Some college':1,'Undergrad':2, 'Grad':3, 'Doctorate':4}\n",
        "inv_dict = {v: k for k, v in ed_dict.items()}\n",
        "plt.figure(figsize = (20, 16))\n",
        "#df.groupby('education')['income'].mean()\n",
        "plt.bar(range(len(inv_dict.keys())),df.groupby('education')['income'].mean(),  tick_label=list(ed_dict.keys()))\n",
        "plt.xlabel('education')\n",
        "plt.ylabel('income')\n",
        "print(np.corrcoef(df['education'], df['income'])[1][0])\n",
        "#correlation exists between education and income"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Ox2Lu7A98i"
      },
      "source": [
        "#### 5.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBr8clmsA98i"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for x in df.select_dtypes(include=np.number).columns.tolist():\n",
        "    #print(x, len(df[x].value_counts()))\n",
        "    \n",
        "num_col = ['age' , 'height', 'kgs', 'bmi'] # these are numerical, income is the target variable\n",
        "for x in num_col:\n",
        "    plt.figure()\n",
        "    plt.scatter(df[x], df['income'])\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel('income')\n",
        "    plt.title('the corellation between income and ' + x + ' is ' + str(np.corrcoef(df[x], df['income'])[1][0]))\n",
        "    \n",
        "    \n",
        "#no obvious dependence between income and any numerical variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# just checking feature importance on multi-linear; one can see that out of the numerical features, only bmi is somewhat relevant.\n",
        "# not relevant to our analysis\n",
        "\n",
        "X = df.drop('income', axis=1)\n",
        "y = df['income']\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "lreg = LinearRegression()\n",
        "lreg.fit(x_train, y_train)\n",
        "y_pred = lreg.predict(x_test)\n",
        "coefs = pd.DataFrame(lreg.coef_, index=X.columns)\n",
        "coefs.plot(kind='barh', figsize=(9, 7))\n",
        "plt.axvline(x=0, color='.5')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_col = ['age' , 'height', 'kgs', 'bmi'] # these are numerical, income is the target variable\n",
        "for x in num_col:\n",
        "    for degree in range(1,5):\n",
        "        X = df[x].values\n",
        "        y = df['income'].values\n",
        "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "        lreg = LinearRegression(fit_intercept=False)\n",
        "        x_poly_train = PolynomialFeatures(degree=degree).fit_transform(x_train.reshape(-1, 1))\n",
        "        x_poly_test = PolynomialFeatures(degree=degree).fit_transform(x_test.reshape(-1, 1))\n",
        "        lreg.fit(x_poly_train, y_train)\n",
        "        y_pred = lreg.predict(x_poly_test)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print('R2 score for {} degree polynomial for {} is {}'.format(degree, x, r2))\n",
        "        \n",
        "#it seems none of the numerical features are good predictors of income\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf8-PTxPA98i"
      },
      "source": [
        "#### 5.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz1kJ75vA98i"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "#check if income is higher for nuclear families or joint families\n",
        "a = df[df['family_type'] == 3]['income'].mean()\n",
        "b = df[df['family_type'] == 2]['income'].mean()\n",
        "print(f'the means for nuclear and joint family respectively are {a} and {b}')\n",
        "#for nuclear families, the mean income is higher\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwa32CgxA98i"
      },
      "source": [
        "#### 5.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK_eRkQEA98i"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "print(np.corrcoef(df[df['manglik'] < 2]['manglik'], df[df['manglik'] < 2]['income'])[1][0])\n",
        "\n",
        "#plot between manglik and income\n",
        "plt.plot(df[df['manglik'] < 2]['manglik'], df[df['manglik'] < 2]['income'], 'o')\n",
        "\n",
        "\n",
        "# very weak negative correlation between being manglik and income."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JngK8y4A98i"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 6:  Calculate the Gini Index  [5 points total] </h3>    <br />\n",
        "\n",
        "\n",
        "Gini coefficients are often used to quantify income inequality, read more [here](http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm).\n",
        "\n",
        "The Gini coefficient is defined by the formula:\n",
        "\n",
        "$G = \\dfrac{ \\sum_{i=1}^{n} (2i - n - 1) x_i}{n  \\sum_{i=1}^{n} x_i}$\n",
        "\n",
        "where $x$ is an observed value, $n$ is the number of values observed and $i$ is the rank of values in **ascending** order.\n",
        "\n",
        "A Gini Index of 0 implies perfect income equality, whereas a gini index close to 1 implies a concentration of wealth among the richest few.\n",
        "<br /><br />\n",
        "**6.1** [3 pts] Based on the above formula, calculate the Gini coffient for the income of the participants of this dataset\n",
        "<br /><br />\n",
        "**6.2** [2 pts] Compare your gini index with other countries\n",
        "\n",
        "According to the [world bank estimate](https://www.indexmundi.com/facts/indicators/SI.POV.GINI/rankings) the gini index of South Africa is 0.6 while that of Ukrain is 0.25. \n",
        "\n",
        "Based on your calculated gini index value for this dataset, what is your conclusion on the income disparity in the three countries?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUiFcdhFA98i"
      },
      "source": [
        "### Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unyR6BnDA98j"
      },
      "source": [
        "#### 6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvXkHDr5A98j",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "def gini(y):\n",
        "    x = np.sort(y.values)\n",
        "    n, d = 0, 0\n",
        "    for i in range(len(x)):\n",
        "        n += (2*i - len(x) -1)*x[i]\n",
        "        d += x[i]\n",
        "    return n/(d*len(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gini(df['income'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "280vSIBVA98j"
      },
      "source": [
        "#### 6.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hb2Xshq4A98j"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "gini_df = pd.read_csv('data/gini.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gini_df['Value'].idxmin(np.abs(gini_df['Value'] - 100*gini(df['income'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.abs(gini_df['Value'] - 100*gini(df['income'])).argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gini_df.iloc[14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#somewhat equal distribution of income, closest to Costa Rica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E795525CA98j"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "<h3 style=\"color:black;background-color:#F6E6E2\"> Question 7:  Multi-Linear Regression [Optional] </h3>    <br />\n",
        "\n",
        "\n",
        "\n",
        "Now we increase the scope of our analysis to solve another problem that is related to income of the participants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u44e_AnQA98j"
      },
      "source": [
        "![](https://github.com/hargun3045/blog-dump/blob/master/modi.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3fXOlaOA98j"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "\n",
        "Owing to a large number of people underreporting their income to evade taxes, the Income Tax Department of India wants you to build a machine learning model that can predict the income of a given tax-payer based on commonly available information.\n",
        "\n",
        "This will help the department red flag suspected individuals who may show discernable trends of earing more but are excessively under-reporting on their annual income.\n",
        "\n",
        "The goal is to build the best model with the given dataset, using both categorical and continuous predictors that are available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Iqy3pxA98j"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#F6E6E2\">\n",
        "\n",
        "Fit a multiple linear regression model to the training set.\n",
        "Use the `sklearn` library.\n",
        "\n",
        "#### Deliverables\n",
        "Your code should be contained in a Jupyter notebook cell.  An appropriate level of comments is necessary.  Your code should run and output the required outputs described below.\n",
        "\n",
        "#### Required Outputs\n",
        "- Fit a multiple linear regression model on the training set\n",
        "- Predict on train and test sets\n",
        "- Calculate the MSE for the train & test set\n",
        "- Report the $R^2$ score on the test set.\n",
        "- Make a plot of Residuals vs Log of predicted values $\\hat{y}$, with residuals on the $Y$-axis and predicted values on the $X$-axis. Use the formula ${\\epsilon} = y - \\hat{y}$ to compute the residual values. Include a horizontal line denoting the zero residual value on the $Y$-axis.\n",
        "- Plot a histogram of the magnitudes of the residuals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/income_prediction.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6y-ffB1A98k"
      },
      "outputs": [],
      "source": [
        "# Here we use another efficient way of splitting the datset into train and test sets using a \"mask\"\n",
        "\n",
        "#You can just run the code below, and just use df_train and df_test for this part of the homework directly\n",
        "\n",
        "#df = pd.read_csv('data/income_prediction.csv')\n",
        "\n",
        "mask = np.ones(len(df))\n",
        "\n",
        "# Using indices only\n",
        "\n",
        "itrain, itest = train_test_split(range(len(df)),train_size=0.8,random_state = 25)\n",
        "\n",
        "#setting all test indices as zero\n",
        "mask[itest] = 0\n",
        "\n",
        "# Converting mask into a boolean expression\n",
        "\n",
        "mask = mask==1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sGTxWqjA98k"
      },
      "outputs": [],
      "source": [
        "df_train = df[mask] # this will give you a dataframe of only training indicies\n",
        "df_test = df[~mask] # this will give you a dataframe of only test indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qBmrXPA98k"
      },
      "outputs": [],
      "source": [
        "# A quick look of the training dataframe\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing out codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basline LinReg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU2W-enUA98k"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(df_train.drop('income', axis=1), df_train['income'])\n",
        "y_pred = model.predict(df_test.drop('income', axis=1))\n",
        "\n",
        "#mse for train test\n",
        "mse_train = mean_squared_error(df_train['income'], model.predict(df_train.drop('income', axis=1)))\n",
        "\n",
        "#mse for test set\n",
        "mse_test = mean_squared_error(df_test['income'], y_pred)\n",
        "\n",
        "#r-squared for test set\n",
        "r2_test = r2_score(df_test['income'], y_pred)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"the mse train is \", mse_train)\n",
        "print(\"the mse test is \", mse_test)\n",
        "print(\"the r2 score on test set is \", r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forward Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = list(df.columns)\n",
        "cols.remove('income')\n",
        "succ = []\n",
        "k = len(cols)\n",
        "mse_list = []\n",
        "for j in range(k):\n",
        "    res = '' \n",
        "    ref_mse = 100000000000\n",
        "    for i in cols:\n",
        "        model = LinearRegression()\n",
        "        x, y  = df[succ + [i]], df['income']\n",
        "        x_train, x_val, y_train, y_val = train_test_split(x, y, train_size = 0.8, random_state = 42)\n",
        "        model.fit(x_train.values, y_train.values)\n",
        "        yv_pred = model.predict(x_val.values)\n",
        "        mse = mean_squared_error(y_val, yv_pred)\n",
        "        if (mse < ref_mse):\n",
        "            res = i\n",
        "            ref_mse = mse\n",
        "    cols.remove(res)\n",
        "    succ.append(res)\n",
        "    print(succ, ref_mse)\n",
        "    mse_list.append(ref_mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse_list[np.array(mse_list).argmin()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cols = ['city', 'status', 'living', 'age', 'height', 'employed', 'drinking', 'smoking', 'complexion', 'body', 'values', 'family_type', 'caste_imp', 'education', 'eating', 'gender', 'manglik']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(df_train[df_cols], df_train['income'])\n",
        "y_pred = model.predict(df_test[df_cols])\n",
        "\n",
        "#mse for train test\n",
        "mse_train = mean_squared_error(df_train['income'], model.predict(df_train[df_cols]))\n",
        "\n",
        "#mse for test set\n",
        "mse_test = mean_squared_error(df_test['income'], y_pred)\n",
        "\n",
        "#r-squared for test set\n",
        "r2_test = r2_score(df_test['income'], y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"the mse train is \", mse_train)\n",
        "print(\"the mse test is \", mse_test)\n",
        "print(\"the r2 score on test set is \", r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in df_cols:\n",
        "    plt.figure()\n",
        "    plt.scatter(df[i], df['income'])\n",
        "    plt.xlabel(i)\n",
        "    plt.ylabel('income')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(a, b):\n",
        "    c = [x for x in a if x in b]\n",
        "    return c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final attempt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = np.ones(len(df))\n",
        "# Using indices only\n",
        "itrain, itest = train_test_split(range(len(df)),train_size=0.8,random_state = 25)\n",
        "#setting all test indices as zero\n",
        "mask[itest] = 0\n",
        "# Converting mask into a boolean expression\n",
        "mask = mask==1\n",
        "df_cols = ['city', 'status', 'living', 'age', 'height', 'employed', 'drinking', 'smoking', 'complexion', 'body', 'values', 'family_type', 'caste_imp', 'education', 'eating', 'gender', 'manglik']\n",
        "cat_cols = [\"eating\" , \"status\" , \"marital_status\" , \"family_type\" , \"city\", \"manglik\", \"horoscope\", \"drinking\", \"smoking\", \"values\", \"complexion\", \"caste_imp\", \"living\", \"education\", \"city\"]\n",
        "data_df = pd.get_dummies(df,columns=cat_cols,drop_first=True)\n",
        "cat_cols_1 = intersection(df_cols, cat_cols)\n",
        "data_df = pd.get_dummies(df,columns=cat_cols_1,drop_first=True)\n",
        "df_train = data_df[mask] # this will give you a dataframe of only training indicies\n",
        "df_test = data_df[~mask] # this will give you a dataframe of only test indicies\n",
        "model = LinearRegression()\n",
        "model.fit(df_train.drop('income', axis=1), df_train['income'])\n",
        "y_pred = model.predict(df_test.drop('income', axis=1))\n",
        "#mse for train test\n",
        "mse_train = mean_squared_error(df_train['income'], model.predict(df_train.drop('income', axis=1)))\n",
        "#mse for test set\n",
        "mse_test = mean_squared_error(df_test['income'], y_pred)\n",
        "#r-squared for test set\n",
        "r2_test = r2_score(df_test['income'], y_pred)\n",
        "print(\"the mse train is \", mse_train)\n",
        "print(\"the mse test is \", mse_test)\n",
        "print(\"the r2 score on test set is \", r2_test)\n",
        "#Make a plot of Residuals vs Log of predicted values\n",
        "residuals = df_test['income'] - y_pred\n",
        "#Include a horizontal line denoting the zero residual value \n",
        "plt.figure()\n",
        "plt.plot(np.log(y_pred), residuals, 'o')\n",
        "plt.plot(np.log(y_pred), [0 for i in range(len(y_pred))])\n",
        "plt.xlabel('Log of Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "#Plot a histogram of the magnitudes of the residuals.\n",
        "plt.figure()\n",
        "plt.hist((residuals), bins = 20)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim(-60000, 60000)\n",
        "#Plot a histogram of the magnitudes of the absolute residuals.\n",
        "plt.figure()\n",
        "plt.hist(abs(residuals), bins = 20)\n",
        "plt.xlabel('Absolute Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim(0, 60000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By making dummies  of the categorical variables; which we have seen are the more important predictors; we have made our model more predictive."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "3751913ea9f5bd031e0b6a9f249a184a00fb379186ae8976a2500bce67b98d17"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
